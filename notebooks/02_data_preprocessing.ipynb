{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Urban Pulse - Data Preprocessing\n",
        "\n",
        "## Data Cleaning and Feature Engineering\n",
        "\n",
        "This notebook handles:\n",
        "- Missing value imputation\n",
        "- Outlier detection and handling\n",
        "- Datetime parsing and temporal feature creation\n",
        "- Derived feature engineering (rush hour, traffic stress levels)\n",
        "- Data quality documentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "from data_processing import (\n",
        "    load_data,\n",
        "    inspect_data,\n",
        "    handle_missing_values,\n",
        "    handle_outliers,\n",
        "    parse_datetime,\n",
        "    create_rush_hour_feature,\n",
        "    create_traffic_stress_level,\n",
        "    preprocess_pipeline,\n",
        "    load_and_clean_data\n",
        ")\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Raw Data\n",
        "\n",
        "Load the dataset from the exploration notebook or directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw data\n",
        "data_path = '../data/raw/Metro_Interstate_Traffic_Volume.csv'\n",
        "\n",
        "try:\n",
        "    df_raw = load_data(data_path)\n",
        "    print(f\"✓ Raw data loaded: {df_raw.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠️  Please run 01_data_exploration.ipynb first or ensure data file exists\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Run Complete Preprocessing Pipeline\n",
        "\n",
        "The preprocessing pipeline handles all cleaning and feature engineering steps automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run complete preprocessing pipeline\n",
        "df_processed, preprocessing_report = preprocess_pipeline(\n",
        "    df_raw,\n",
        "    target_column='traffic_volume',\n",
        "    date_column='date_time',\n",
        "    missing_strategy='forward_fill',  # Good for time series data\n",
        "    outlier_method='cap'  # Cap outliers rather than remove\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Verify Preprocessing Results\n",
        "\n",
        "Check that all features were created correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display new features created\n",
        "print(\"New Features Created:\")\n",
        "print(\"=\"*60)\n",
        "new_features = ['year', 'month', 'day', 'hour', 'day_of_week', 'is_weekend',\n",
        "                'is_rush_hour', 'rush_hour_type', 'traffic_stress_level', 'is_congested']\n",
        "\n",
        "for feature in new_features:\n",
        "    if feature in df_processed.columns:\n",
        "        print(f\"✓ {feature}\")\n",
        "        if df_processed[feature].dtype == 'object':\n",
        "            print(f\"    Values: {df_processed[feature].value_counts().to_dict()}\")\n",
        "        else:\n",
        "            print(f\"    Range: {df_processed[feature].min()} - {df_processed[feature].max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save Processed Data\n",
        "\n",
        "Save the cleaned and processed dataset for use in EDA and ML notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save processed data\n",
        "output_path = '../data/processed/traffic_cleaned.csv'\n",
        "df_processed.to_csv(output_path, index=False)\n",
        "print(f\"✓ Processed data saved to: {output_path}\")\n",
        "print(f\"  Shape: {df_processed.shape}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
