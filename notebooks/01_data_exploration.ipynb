{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Urban Pulse - Data Exploration\n",
        "\n",
        "## Initial Data Exploration and Understanding\n",
        "\n",
        "This notebook performs the initial exploration of the traffic volume dataset to understand its structure, quality, and basic characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "from data_processing import load_data, inspect_data\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load the Dataset\n",
        "\n",
        "First, we load the raw traffic volume dataset from the data/raw directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "# NOTE: Update this path to match your actual data file location\n",
        "data_path = '../data/raw/Metro_Interstate_Traffic_Volume.csv'\n",
        "\n",
        "# Alternative: If using a different dataset name, update accordingly\n",
        "# data_path = '../data/raw/traffic_volume.csv'\n",
        "\n",
        "try:\n",
        "    df_raw = load_data(data_path)\n",
        "    print(f\"\\nDataset loaded: {df_raw.shape[0]} rows × {df_raw.shape[1]} columns\")\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠️  Data file not found!\")\n",
        "    print(\"Please download the Metro Interstate Traffic Volume dataset from:\")\n",
        "    print(\"  - Kaggle: https://www.kaggle.com/datasets\")\n",
        "    print(\"  - UCI ML Repository: https://archive.ics.uci.edu/ml/index.php\")\n",
        "    print(\"\\nPlace the CSV file in: data/raw/Metro_Interstate_Traffic_Volume.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initial Data Inspection\n",
        "\n",
        "Let's examine the structure and basic information about the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "print(\"First 5 rows:\")\n",
        "print(df_raw.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Dataset Info:\")\n",
        "print(\"=\"*60)\n",
        "df_raw.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive data quality report\n",
        "data_quality_report = inspect_data(df_raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display basic statistics for numeric columns\n",
        "print(\"=\"*60)\n",
        "print(\"DESCRIPTIVE STATISTICS (Numeric Columns)\")\n",
        "print(\"=\"*60)\n",
        "print(df_raw.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display value counts for categorical columns\n",
        "print(\"=\"*60)\n",
        "print(\"CATEGORICAL COLUMNS ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "categorical_cols = df_raw.select_dtypes(include=['object']).columns.tolist()\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(df_raw[col].value_counts().head(10))\n",
        "    print(f\"Unique values: {df_raw[col].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Types and Column Information\n",
        "\n",
        "Understanding what each column represents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column names and data types\n",
        "print(\"Column Information:\")\n",
        "print(\"=\"*60)\n",
        "for i, (col, dtype) in enumerate(zip(df_raw.columns, df_raw.dtypes), 1):\n",
        "    print(f\"{i:2d}. {col:25s} : {str(dtype):15s} | Non-null: {df_raw[col].notna().sum():6d}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Check for Duplicates and Data Quality Issues\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicate rows\n",
        "duplicate_count = df_raw.duplicated().sum()\n",
        "print(f\"Duplicate rows: {duplicate_count}\")\n",
        "\n",
        "if duplicate_count > 0:\n",
        "    print(\"\\nSample duplicate rows:\")\n",
        "    print(df_raw[df_raw.duplicated(keep=False)].head(10))\n",
        "else:\n",
        "    print(\"✓ No duplicate rows found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initial Visualizations\n",
        "\n",
        "Quick visualizations to understand the data distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick histogram of traffic volume (if column exists)\n",
        "if 'traffic_volume' in df_raw.columns:\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    df_raw['traffic_volume'].hist(bins=50, ax=ax, edgecolor='black', alpha=0.7)\n",
        "    ax.set_xlabel('Traffic Volume', fontsize=12)\n",
        "    ax.set_ylabel('Frequency', fontsize=12)\n",
        "    ax.set_title('Initial Traffic Volume Distribution', fontsize=14, fontweight='bold')\n",
        "    ax.axvline(df_raw['traffic_volume'].mean(), color='red', linestyle='--', \n",
        "               label=f'Mean: {df_raw[\"traffic_volume\"].mean():.0f}')\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"⚠️  'traffic_volume' column not found. Please check column names.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary and Next Steps\n",
        "\n",
        "**Key Findings:**\n",
        "- Dataset shape and structure\n",
        "- Missing values identified\n",
        "- Data types confirmed\n",
        "- Initial quality assessment complete\n",
        "\n",
        "**Next Steps:**\n",
        "- Proceed to `02_data_preprocessing.ipynb` for data cleaning and feature engineering\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
